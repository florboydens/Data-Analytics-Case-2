{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" %pip install matplotlib\n",
    "%pip install plotly\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install datetime\"\"\"\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearvars():    \n",
    "    for el in sorted(globals()):\n",
    "        if '__' not in el:\n",
    "                print(f'deleted: {el}')\n",
    "                del el\n",
    "clearvars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'dataRaw/'\n",
    "dataRaw = pd.read_csv(base_path + 'data.csv', sep=',', low_memory=False)\n",
    "holidays_events = pd.read_csv(base_path + 'holidays_events(India).csv', sep=';')\n",
    "items = pd.read_csv(base_path + 'items.csv', sep=';', low_memory=False)\n",
    "oilRaw = pd.read_csv(base_path + 'oil(India).csv', sep=',', skipinitialspace=True)\n",
    "stores = pd.read_csv(base_path + 'stores.csv', sep=';', encoding='ISO-8859-1')\n",
    "testRaw = pd.read_csv(base_path + 'test.csv', sep=',')\n",
    "transactions = pd.read_csv(base_path + 'transactions.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" test.to_csv('data/test.csv', index=False)\\n> git push origin main:main\\nremote: error: Trace: 25213f19d457fb2989564964b10ab27c2fb682233e594fb81ff2ed78998776c2        \\nremote: error: See https://gh.io/lfs for more information.        \\nremote: error: File data/test.csv is 120.32 MB; this exceeds GitHub's file size limit of 100.00 MB        \\nremote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.        \\nTo https://github.com/florboydens/Data-Analytics-Case-2.git\\n ! [remote rejected] main -> main (pre-receive hook declined)\\nerror: failed to push some refs to 'https://github.com/florboydens/Data-Analytics-Case-2.git' \""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = testRaw.copy()\n",
    "test['date'] = pd.to_datetime(test['date'], format='%Y-%m-%d')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "\"\"\" test.to_csv('data/test.csv', index=False)\n",
    "> git push origin main:main\n",
    "remote: error: Trace: 25213f19d457fb2989564964b10ab27c2fb682233e594fb81ff2ed78998776c2        \n",
    "remote: error: See https://gh.io/lfs for more information.        \n",
    "remote: error: File data/test.csv is 120.32 MB; this exceeds GitHub's file size limit of 100.00 MB        \n",
    "remote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.        \n",
    "To https://github.com/florboydens/Data-Analytics-Case-2.git\n",
    " ! [remote rejected] main -> main (pre-receive hook declined)\n",
    "error: failed to push some refs to 'https://github.com/florboydens/Data-Analytics-Case-2.git' \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataRaw.copy()\n",
    "data['date'] = pd.to_datetime(dataRaw['date'], format='%Y-%m-%d')\n",
    "data['unit_sales'] = dataRaw['unit_sales'].round(2)\n",
    "data['onpromotion'].fillna(False, inplace=True)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "\"\"\" \n",
    "data.to_csv('data/data.csv', index=False)\n",
    "...\n",
    "Zelfde reden als de Test file, te groot\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = oilRaw['dcoilwtico;;'].str.contains('%')\n",
    "oilExtra = oilRaw[mask].copy()\n",
    "oil = oilRaw[~mask].copy()\n",
    "oil.reset_index(drop=True, inplace=True)\n",
    "oil['dcoilwtico;;'] = oil['dcoilwtico;;'].str.replace(';', '')\n",
    "oil['dcoilwtico;;'] = oil['dcoilwtico;;'].apply(lambda x: x.strip())\n",
    "oil = oil[~(oil['dcoilwtico;;'] == '')]\n",
    "try:\n",
    "    oil['dcoilwtico;;'] = oil['dcoilwtico;;'].astype(float).round(2)\n",
    "except:\n",
    "    oil.dropna(subset=['dcoilwtico;;'], inplace=True)\n",
    "oil.rename(columns={'dcoilwtico;;': 'dcoilwtico'}, inplace=True)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "oil.to_csv('data/oil.csv', index=False)\n",
    "oilExtra.to_csv('data/oilExtra.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['date'] = pd.to_datetime(test['date'], format='%Y-%m-%d')\n",
    "transactions['month_day'] = transactions['date'].dt.strftime('%m-%d')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "transactions.to_csv('data/transactions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_events = pd.read_csv(base_path + 'holidays_events(India).csv', sep=';')\n",
    "\n",
    "holidays_events = holidays_events.drop(columns=['type'])\n",
    "holidays_events.dropna(subset=['date'], inplace=True)\n",
    "holidays_events['date'] = holidays_events['date'].str.replace(' ', '/')\n",
    "holidays_events['date'] = holidays_events['date'].str.replace('mrt', 'mar')\n",
    "holidays_events['date'] = holidays_events['date'].str.replace('mei', 'may')\n",
    "holidays_events['date'] = holidays_events['date'].str.replace('okt', 'oct')\n",
    "holidays_events = holidays_events.drop_duplicates()\n",
    "holidays_events['date'] = pd.to_datetime(holidays_events['date'], format='%d/%b')   #.dt.strftime('%Y-%m-%d')\n",
    "# if the date is the same from earlier in the dataset, drop the row.\n",
    "holidays_events = holidays_events[~holidays_events['date'].duplicated()]\n",
    "holidays_events['month_day'] = holidays_events['date'].dt.strftime('%m-%d')\n",
    "holidays_events = holidays_events.sort_values('date')\n",
    "holidays_events = holidays_events.reindex(columns=['date', 'month_day', 'description', 'transferred'])\n",
    "holidays_events.rename(columns={'transferred': 'type'}, inplace=True)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "holidays_events.to_csv('data/holidays_events.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analytics-kernel-case-2",
   "language": "python",
   "name": "data-analytics-kernel-case-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
